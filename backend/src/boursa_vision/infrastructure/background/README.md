# SystÃ¨me d'Archivage Automatique des DonnÃ©es de MarchÃ©

Ce module fournit un systÃ¨me d'archivage continu des donnÃ©es financiÃ¨res utilisant Celery et YFinance pour maintenir un historique complet des prix et volumes des instruments financiers.

## ðŸŽ¯ Objectif

Ã‰viter la perte de prÃ©cision des donnÃ©es historiques en archivant automatiquement :
- **DonnÃ©es minute** toutes les 5 minutes pendant les heures de marchÃ©
- **DonnÃ©es horaires** chaque heure 
- **DonnÃ©es quotidiennes** Ã  18h00 UTC (aprÃ¨s fermeture des marchÃ©s)
- **DonnÃ©es hebdomadaires** le dimanche Ã  20h00

## ðŸ—ï¸ Architecture

```
src/infrastructure/background/
â”œâ”€â”€ __init__.py                 # Exports publics du module
â”œâ”€â”€ celery_app.py              # Configuration Celery + scheduler
â”œâ”€â”€ market_data_archiver.py    # Service d'archivage principal
â”œâ”€â”€ tasks.py                   # TÃ¢ches Celery
â”œâ”€â”€ cli.py                     # Interface en ligne de commande
â””â”€â”€ README.md                  # Cette documentation
```

### Design Patterns UtilisÃ©s

- **Strategy Pattern** : DiffÃ©rentes stratÃ©gies d'archivage selon l'intervalle
- **Repository Pattern** : AccÃ¨s aux donnÃ©es via les repositories existants
- **Observer Pattern** : Events Celery pour monitoring  
- **Factory Pattern** : CrÃ©ation des entitÃ©s MarketData
- **Command Pattern** : TÃ¢ches Celery comme commandes

## ðŸ“Š Indices SupportÃ©s

Le systÃ¨me archive automatiquement les donnÃ©es pour :

- **CAC 40** : 40 plus grandes capitalisations franÃ§aises
- **NASDAQ 100** : 100 plus grandes capitalisations technologiques
- **FTSE 100** : Principales capitalisations britanniques  
- **DAX 40** : Principales capitalisations allemandes

## ðŸš€ DÃ©marrage

### 1. Lancement via Docker (RecommandÃ©)

```bash
# DÃ©marrer tous les services incluant Celery
cd docker
docker-compose -f docker-compose.dev.yml up -d

# VÃ©rifier que les workers sont dÃ©marrÃ©s
docker-compose -f docker-compose.dev.yml ps
```

### 2. Lancement manuel

```bash
# Terminal 1 : Worker Celery
cd backend
poetry run python src/infrastructure/background/cli.py worker

# Terminal 2 : Scheduler Celery Beat
poetry run python src/infrastructure/background/cli.py beat
```

## ðŸ› ï¸ Interface CLI

Le systÃ¨me fournit une CLI complÃ¨te pour la gestion manuelle :

### Commandes Principales

```bash
# Archivage manuel de tous les symboles
poetry run python src/infrastructure/background/cli.py archive --interval 1d

# Archivage de symboles spÃ©cifiques
poetry run python src/infrastructure/background/cli.py archive-symbols AAPL MSFT GOOGL --interval 1h

# Statut du systÃ¨me d'archivage
poetry run python src/infrastructure/background/cli.py status

# Test des connexions
poetry run python src/infrastructure/background/cli.py test-connection

# Aide dÃ©taillÃ©e
poetry run python src/infrastructure/background/cli.py --help
```

### Options d'Intervalle

- `1m` : 1 minute (donnÃ©es haute frÃ©quence)
- `5m` : 5 minutes  
- `15m` : 15 minutes
- `30m` : 30 minutes
- `1h` : 1 heure
- `1d` : 1 jour (par dÃ©faut)
- `1w` : 1 semaine
- `1M` : 1 mois

## ðŸ“… Programmation Automatique

### TÃ¢ches Celery Beat

| TÃ¢che | FrÃ©quence | Intervalle | Description |
|-------|-----------|------------|-------------|
| `archive-market-data-frequent` | Toutes les 5 min | 1m | DonnÃ©es haute frÃ©quence |
| `archive-market-data-hourly` | Toutes les heures | 1h | DonnÃ©es horaires |
| `archive-market-data-daily` | 18h00 UTC | 1d | DonnÃ©es quotidiennes |
| `archive-market-data-weekly` | Dim 20h00 | 1w | DonnÃ©es hebdomadaires |
| `health-check` | Toutes les 30 min | - | SantÃ© du systÃ¨me |

### Configuration des Horaires

Les horaires sont optimisÃ©s pour les marchÃ©s financiers :
- **DonnÃ©es frÃ©quentes** : Pendant les heures d'ouverture
- **DonnÃ©es quotidiennes** : AprÃ¨s fermeture (18h00 UTC)
- **DonnÃ©es hebdomadaires** : Weekend (dimanche)

## ðŸ—„ï¸ Stockage des DonnÃ©es

### Base de DonnÃ©es TimescaleDB

```sql
-- Table principale : market_data
-- Hypertable optimisÃ©e pour les sÃ©ries temporelles
CREATE TABLE market_data (
    time TIMESTAMPTZ NOT NULL,
    symbol VARCHAR(20) NOT NULL,
    interval_type VARCHAR(5) NOT NULL,
    open_price NUMERIC(15,4),
    high_price NUMERIC(15,4), 
    low_price NUMERIC(15,4),
    close_price NUMERIC(15,4),
    adjusted_close NUMERIC(15,4),
    volume BIGINT,
    source VARCHAR(20) DEFAULT 'yfinance',
    created_at TIMESTAMPTZ DEFAULT NOW(),
    PRIMARY KEY (time, symbol, interval_type)
);
```

### Index OptimisÃ©s

- `idx_market_data_symbol_time` : RequÃªtes par symbole
- `idx_market_data_interval` : RequÃªtes par intervalle
- Partitioning automatique par TimescaleDB

## ðŸ“ˆ Monitoring et Logs

### Logs Structured

```json
{
  "timestamp": "2024-08-14T10:30:00Z",
  "level": "INFO", 
  "logger": "market_data_archiver",
  "message": "Archival completed: 120/125 symbols (96.0% success rate)",
  "context": {
    "interval": "1d",
    "successful": 120,
    "failed": 5,
    "duration_seconds": 245
  }
}
```

### MÃ©triques Celery

- **Worker status** : SantÃ© des workers
- **Task success rate** : Taux de succÃ¨s des tÃ¢ches
- **Latency** : Temps d'exÃ©cution des tÃ¢ches
- **Error tracking** : Suivi des erreurs

## âš™ï¸ Configuration

### Variables d'Environnement

```bash
# Celery
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# YFinance Rate Limiting
YFINANCE_RATE_LIMIT=10
YFINANCE_BATCH_SIZE=50
YFINANCE_TIMEOUT=30
YFINANCE_RETRY_ATTEMPTS=3

# Cache
MARKET_DATA_CACHE_TTL=300
REAL_TIME_DATA_CACHE_TTL=60
```

### Personnalisation des Indices

Pour ajouter de nouveaux indices, modifier `market_data_archiver.py` :

```python
def _load_financial_indices(self) -> Dict[str, List[str]]:
    return {
        "custom_index": [
            "SYMBOL1", "SYMBOL2", "SYMBOL3"
        ],
        # ... autres indices
    }
```

## ðŸ”§ Maintenance

### Nettoyage des DonnÃ©es

```bash
# Nettoyer les donnÃ©es anciennes (> 365 jours)
poetry run celery -A src.infrastructure.background.celery_app call \
  src.infrastructure.background.tasks.cleanup_old_data_task \
  --args='[365]'
```

### Monitoring des Performances

```bash
# Statut des workers Celery
poetry run celery -A src.infrastructure.background.celery_app status

# Inspection des tÃ¢ches actives
poetry run celery -A src.infrastructure.background.celery_app inspect active

# Statistiques des tÃ¢ches
poetry run celery -A src.infrastructure.background.celery_app inspect stats
```

## ðŸš¨ Gestion d'Erreurs

### StratÃ©gies de Resilience

1. **Retry automatique** : 3 tentatives avec dÃ©lai croissant
2. **Rate limiting** : Respect des limites YFinance (200ms entre requÃªtes)
3. **Circuit breaker** : ArrÃªt temporaire en cas d'erreurs rÃ©pÃ©tÃ©es
4. **Graceful degradation** : Continuation mÃªme si certains symboles Ã©chouent

### Monitoring des Erreurs

- **Logs centralisÃ©s** : Tous les Ã©checs sont loggÃ©s
- **Alertes** : Notifications en cas de taux d'Ã©chec > 20%
- **MÃ©triques** : Suivi des performances via Celery

## ðŸ§ª Tests

### Tests d'IntÃ©gration

```bash
# Test manuel d'archivage
poetry run python src/infrastructure/background/cli.py archive-symbols AAPL --interval 1d

# Test des connexions
poetry run python src/infrastructure/background/cli.py test-connection

# VÃ©rification du statut
poetry run python src/infrastructure/background/cli.py status
```

### Tests de Performance

Le systÃ¨me est conÃ§u pour traiter :
- **~200 symboles** en moins de 5 minutes
- **Taux de succÃ¨s** > 95% en conditions normales
- **Latence** < 2 secondes par symbole

## ðŸ“š IntÃ©gration

### Utilisation dans le Code

```python
from src.infrastructure.background.market_data_archiver import MarketDataArchiver

# Instance de l'archiveur
archiver = MarketDataArchiver()

# Archivage programmatique
report = await archiver.archive_all_symbols("1h")

# Statut du systÃ¨me
status = await archiver.get_archival_status()
```

### Ã‰vÃ©nements Domaine

```python
from src.domain.events.market_events import MarketDataUpdatedEvent

# L'archivage gÃ©nÃ¨re automatiquement des Ã©vÃ©nements
# pour notification des autres services
```

## ðŸ”® Ã‰volutions Futures

### FonctionnalitÃ©s PrÃ©vues

1. **Sources multiples** : Alpha Vantage, IEX Cloud, Polygon
2. **Compression intelligente** : Optimisation du stockage
3. **API GraphQL** : RequÃªtes flexibles des donnÃ©es archivÃ©es
4. **Machine Learning** : DÃ©tection d'anomalies dans les donnÃ©es
5. **Webhooks** : Notifications en temps rÃ©el des Ã©vÃ©nements

### Optimisations

1. **ParallÃ©lisation** : Traitement concurrent par indice
2. **Caching intelligent** : Ã‰viter les requÃªtes redondantes
3. **Compression** : RÃ©duction de l'espace disque
4. **Partitioning** : AmÃ©lioration des performances de requÃªte

---

## ðŸ†˜ Support

En cas de problÃ¨me :

1. **VÃ©rifier les logs** : `docker-compose logs celery-worker`
2. **Statut systÃ¨me** : `poetry run python cli.py status`
3. **Test connexions** : `poetry run python cli.py test-connection`
4. **Restart services** : `docker-compose restart celery-worker celery-beat`

Le systÃ¨me d'archivage est conÃ§u pour Ãªtre robuste et auto-rÃ©parateur, mais en cas de problÃ¨me persistant, consulter les logs dÃ©taillÃ©s.
